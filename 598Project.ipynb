{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1CPuNJQLUGr"
      },
      "outputs": [],
      "source": [
        "#used https://github.com/carlini/audio_adversarial_examples for the CW attack\n",
        "#the second part was not finished due to time constraint, still a work in progress :)\n",
        "\n",
        "import scipy.io.wavfile as wav\n",
        "import argparse\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "sys.path.append(\"DeepSpeech\")\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "!apt-get install -qq sox\n",
        "!pip install -q deepspeech-gpu==0.6.1 youtube-dl\n",
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/deepspeech-0.6.1-models.tar.gz\n",
        "!tar xvfz deepspeech-0.6.1-models.tar.gz\n",
        "\n",
        "!pip install util\n",
        "\n",
        "import DeepSpeech\n",
        "\n",
        "tf.load_op_library = lambda x: x\n",
        "tmp = os.path.exists\n",
        "os.path.exists = lambda x: True\n",
        "\n",
        "os.path.exists = tmp\n",
        "\n",
        "from util.text import ctc_label_dense_to_sparse\n",
        "from tf_logits3 import get_logits\n",
        "from tqdm import tqdm\n",
        "toks = \" abcdefghijklmnopqrstuvwxyz'-\"\n",
        "\n",
        "DeepSpeech.TrainingCoordinator.__init__ = lambda x: None\n",
        "\n",
        "DeepSpeech.TrainingCoordinator.start = lambda x: None\n",
        "import loss\n",
        "# Use the same decode framework as the CW attack\n",
        "class Decoder:\n",
        "\tdef __init__(self, sess, max_audio_len):\n",
        "\t\tself.sess = sess\n",
        "\t\tself.max_audio_len = max_audio_len\n",
        "\t\tself.original = original = tf.Variable(np.zeros((1, max_audio_len), dtype=np.float32), name='qq_original')\n",
        "\t\tself.lengths = lengths = tf.Variable(np.zeros(1, dtype=np.int32), name='qq_lengths')\n",
        "\n",
        "\t\twith tf.variable_scope(\"\", reuse=tf.AUTO_REUSE):\n",
        "\t\t\tlogits, features = get_logits(original, lengths)\n",
        "\n",
        "\t\tself.logits = logits\n",
        "\t\tself.features = features\n",
        "\t\tsaver = tf.train.Saver([x for x in tf.global_variables() if 'qq' not in x.name])\n",
        "\t\tsaver.restore(sess, \"models/session_dump\")\n",
        "\t\tself.decoded, _ = tf.nn.ctc_beam_search_decoder(logits, lengths, merge_repeated=False, beam_width=1000)\n",
        "\n",
        "\tdef transcribe(self, audio, lengths):\n",
        "\t\tsess = self.sess\n",
        "\t\tsess.run(self.original.assign(np.array(audio)))\n",
        "\t\tsess.run(self.lengths.assign((np.array(lengths)-1)//320))\n",
        "\t\tout, logits = sess.run((self.decoded, self.logits))\n",
        "\t\tchars = out[0].values\n",
        "\t\tres = np.zeros(out[0].dense_shape)+len(toks)-1\t\t\n",
        "\t\tfor ii in range(len(out[0].values)):\n",
        "\t\t\tx,y = out[0].indices[ii]\n",
        "\t\t\tres[x,y] = out[0].values[ii]\n",
        "\t\tres = [\"\".join(toks[int(x)] for x in y).replace(\"-\",\"\") for y in res]\n",
        "\t\treturn res[0]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(audio, num):\n",
        "\tglobal maxlen\n",
        "\tglobal D\n",
        "\tglobal ref\n",
        "\taudios = [list(audio)]\n",
        "\tlengths = [int(maxlen * num)]\n",
        "\taudios = np.array(audios)\n",
        "\tres = D.transcribe(audios, lengths)\n",
        "\treturn res"
      ],
      "metadata": {
        "id": "MxS2D_pqdXph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 50\n",
        "y_test = np.zeros(num_samples * 2)\n",
        "roc_auc = np.zeros(3)\n",
        "TD = np.zeros((3, num_samples * 2), dtype = np.float32)\n",
        "count = 0\n",
        "if __name__ == '__main__':\n",
        "\tsess = tf.Session()\n",
        "\tparser = argparse.ArgumentParser(description = None)\n",
        "\tparser.add_argument('--cut', type = float, required = True)\n",
        "\targs = parser.parse_args()\n",
        "\n",
        "\n",
        "\tratio = args.cut\n",
        "\tpbar = tqdm(range(num_samples), unit='steps', ascii = True)\n",
        "\tfor epoch in pbar:\n",
        "\t\tx, y = wav.read(\"librisample\" + str(epoch) + \".wav\")\n",
        "\t\tz, w = wav.read(\"librifinal\" + str(epoch) + \".wav\")\n",
        "\t\tmaxlen = len(y)\n",
        "\n",
        "\t\tD = Decoder(sess, maxlen)\n",
        "\t\tstry = decode(y, 1)\n",
        "\t\tstrw = decode(w, 1)\n",
        "\t\thalfy = decode(y, ratio)\n",
        "\t\thalfw = decode(w, ratio)\n",
        "\n",
        "\t\ts1 = loss.newWER(stry, halfy)\n",
        "\t\ts2 = loss.newCER(stry, halfy)\n",
        "\t\ts3 = loss.lcp(stry, halfy)\n",
        "\n",
        "\t\ty_test[count] = 0\n",
        "\t\tTD[0][count] = float(s1)\n",
        "\t\tTD[1][count] = float(s2)\n",
        "\t\tTD[2][count] = float(s3)\n",
        "\n",
        "\t\tcount += 1\n",
        "\t\ts1 = loss.newWER(strw, halfw)\n",
        "\t\ts2 = loss.newCER(strw, halfw)\n",
        "\t\ts3 = loss.lcp(strw, halfw)\n",
        "\t\t\n",
        "\t\ty_test[count] = 1\n",
        "\t\tTD[0][count] = float(s1)\n",
        "\t\tTD[1][count] = float(s2)\n",
        "\t\tTD[2][count] = float(s3)\n",
        "\t\tcount += 1\n",
        "\n",
        "\tfor i in range(3):\n",
        "\t\tif (i == 2):\n",
        "\t\t\ty_test = 1 - y_test\n",
        "\t\tfpr, tpr, threshold = roc_curve(y_test, TD[i])\n",
        "\t\troc_auc[i] = auc(fpr, tpr)\n",
        "\n",
        "\tprint (\"WER: \" + str(roc_auc[0]) + \" CER: \" + str(roc_auc[1]) + \" LCP: \" + str(roc_auc[2]))"
      ],
      "metadata": {
        "id": "zM-LM0BqdYDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioClassifier (nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        conv_layers = []\n",
        "        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
        "        self.conv1.bias.data.zero_()\n",
        "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
        "        self.conv2.bias.data.zero_()\n",
        "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
        "\n",
        "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.lin = nn.Linear(in_features=64, out_features=10)\n",
        "\n",
        "        # Wrap the Convolutional Blocks\n",
        "        self.conv = nn.Sequential(*conv_layers)\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.ap(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.lin(x)\n",
        "        return x\n",
        "\n",
        "myModel = AudioClassifier()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "myModel = myModel.to(device)\n",
        "next(myModel.parameters()).device"
      ],
      "metadata": {
        "id": "YWr6Ycm8fUjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#partial implemntation of anomalous pattern detection. Work in progress (a lot left to do and optimize)\n",
        "def training(model, train_dl, num_epochs):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,steps_per_epoch=int(len(train_dl)),epochs=num_epochs,anneal_strategy='linear')\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "\n",
        "    for i, data in enumerate(train_dl):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "        correct_prediction += (prediction == labels).sum().item()\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "    num_batches = len(train_dl)\n",
        "    avg_loss = running_loss / num_batches\n",
        "    acc = correct_prediction/total_prediction\n",
        "    print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
        "\n",
        "  print('Finished Training')\n",
        "  \n",
        "num_epochs=2\n",
        "training(myModel, train_dl, num_epochs)\n",
        "\n",
        "def ExtractActivation(flattened_layer, input_data):\n",
        "\n",
        "    return activations\n",
        "\n",
        "def SortAscending(arr):\n",
        "    return np.sort(arr)\n",
        "\n",
        "\n",
        "def NPSS(alpha, k, m):\n",
        "    return npss_score\n",
        "\n",
        "def main(Xz, Xi, alpha_max, D_H0, J):\n",
        "    M = len(D_H0)\n",
        "    ASR = training(training_dataset)\n",
        "    ASRy = SomeFlattenedLayerOfASR\n",
        "    A_H0 = np.zeros((M, J))\n",
        "    A_i = np.zeros(J)\n",
        "    pij = np.zeros(M)\n",
        "    psij = np.zeros(M)\n",
        "    S = {}\n",
        "    alpha = {}\n",
        "    F = {}\n",
        "\n",
        "  \n",
        "    for z in range(M):\n",
        "        for j in range(J):\n",
        "            A_H0[z,j] = ExtractActivation(ASRy, Xz[z])\n",
        "\n",
        "    for j in range(J):\n",
        "        A_i[j] = ExtractActivation(ASRy, Xi)\n",
        "\n",
        "    for i in range(M):\n",
        "        if A_H0[i,j] >= A_i[j]:\n",
        "            pij[i] += 1\n",
        "        else:\n",
        "            pij[i] += 0\n",
        "    pij /= M\n",
        "    pij += 1 / (M + 1)\n",
        "    psij = SortAscending(pij)\n",
        "\n",
        "    for k in range(1, J+1):\n",
        "        S[k] = {}\n",
        "        for y in range(k):\n",
        "            S[k][y] = psij[y]\n",
        "        alpha[k] = max(S[k].values())\n",
        "        F[k] = NPSS(alpha[k], k, k)\n",
        "\n",
        "    k_star = max(F, key=F.get)\n",
        "    return S[k_star], alpha[k_star], F[k_star]"
      ],
      "metadata": {
        "id": "TtdRBOied51K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lcp(x, y):\n",
        "\tx = x.split()\n",
        "\ty = y.split()\n",
        "\tn = len(x)\n",
        "\tm = len(y)\n",
        "\n",
        "\tk = min(n, m)\n",
        "\tidx = 0\n",
        "\tfor i in range(k):\n",
        "\t\tif (x[i] != y[i]):\n",
        "\t\t\tbreak\n",
        "\t\tidx = i + 1\n",
        "\t\n",
        "\treturn idx * 1.0 / max(n, m)"
      ],
      "metadata": {
        "id": "RaFlApg2UuZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def newWER(x, y):\n",
        "\tx = x.split()\n",
        "\ty = y.split()\n",
        "\t\n",
        "\tn = len(x)\n",
        "\tm = len(y)\n",
        "\tk = min(n, m)\n",
        "\td = np.zeros((k + 1) * (k + 1), dtype = np.uint8).reshape(k + 1, k + 1)\n",
        "\n",
        "\tfor i in range(k + 1):\n",
        "\t\tfor j in range(k + 1):\n",
        "\t\t\tif i == 0:\n",
        "\t\t\t\td[0][j] = j\n",
        "\t\t\telif j == 0:\n",
        "\t\t\t\td[i][0] = i\n",
        "\n",
        "\tfor i in range(1, k + 1):\n",
        "\t\tfor j in range(1, k + 1):\n",
        "\t\t\tif (x[i - 1] == y[j - 1]):\n",
        "\t\t\t\td[i][j] = d[i - 1][j - 1]\n",
        "\t\t\telse:\n",
        "\t\t\t\tS = d[i - 1][j - 1] + 1\n",
        "\t\t\t\tI = d[i][j - 1] + 1\n",
        "\t\t\t\tD = d[i - 1][j] + 1\n",
        "\t\t\t\td[i][j] = min(S, I, D)\n",
        "\t\n",
        "\tprint (d[k][k])\n",
        "\treturn d[k][k] * 1.0 / k"
      ],
      "metadata": {
        "id": "dz24sbqPVVuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def WER(x, y):\n",
        "\tx = x.split()\n",
        "\ty = y.split()\n",
        "\t\n",
        "\tn = len(x)\n",
        "\tm = len(y)\n",
        "\tprint (n)\n",
        "\tprint (m)\n",
        "\td = np.zeros((n + 1) * (m + 1), dtype = np.uint8).reshape(n + 1, m + 1)\n",
        "\n",
        "\tfor i in range(n + 1):\n",
        "\t\tfor j in range(m + 1):\n",
        "\t\t\tif i == 0:\n",
        "\t\t\t\td[0][j] = j\n",
        "\t\t\telif j == 0:\n",
        "\t\t\t\td[i][0] = i\n",
        "\n",
        "\tfor i in range(1, n + 1):\n",
        "\t\tfor j in range(1, m + 1):\n",
        "\t\t\tif (x[i - 1] == y[j - 1]):\n",
        "\t\t\t\td[i][j] = d[i - 1][j - 1]\n",
        "\t\t\telse:\n",
        "\t\t\t\tS = d[i - 1][j - 1] + 1\n",
        "\t\t\t\tI = d[i][j - 1] + 1\n",
        "\t\t\t\tD = d[i - 1][j] + 1\n",
        "\t\t\t\td[i][j] = min(S, I, D)\n",
        "\t\n",
        "\tprint (d[n][m])\n",
        "\treturn d[n][m] * 1.0 / n\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-LIOpQbALbYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def newCER(x, y):\n",
        "\tx = x.replace(\" \", \"\")\n",
        "\ty = y.replace(\" \", \"\")\n",
        "\tn = len(x)\n",
        "\tm = len(y)\n",
        "\tk = min(n, m)\n",
        "\td = np.zeros((k + 1) * (k + 1), dtype = np.uint8).reshape(k + 1, k + 1)\n",
        "\n",
        "\tfor i in range(k + 1):\n",
        "\t\tfor j in range(k + 1):\n",
        "\t\t\tif i == 0:\n",
        "\t\t\t\td[0][j] = j\n",
        "\t\t\telif j == 0:\n",
        "\t\t\t\td[i][0] = i\n",
        "\n",
        "\tfor i in range(1, k + 1):\n",
        "\t\tfor j in range(1, k + 1):\n",
        "\t\t\tif (x[i - 1] == y[j - 1]):\n",
        "\t\t\t\td[i][j] = d[i - 1][j - 1]\n",
        "\t\t\telse:\n",
        "\t\t\t\tS = d[i - 1][j - 1] + 1\n",
        "\t\t\t\tI = d[i][j - 1] + 1\n",
        "\t\t\t\tD = d[i - 1][j] + 1\n",
        "\t\t\t\td[i][j] = min(S, I, D)\n",
        "\t\n",
        "\treturn d[k][k] * 1.0 / k\n"
      ],
      "metadata": {
        "id": "Xnz1aG4VdpeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CER(x, y):\n",
        "\tx = x.replace(\" \", \"\")\n",
        "\ty = y.replace(\" \", \"\")\n",
        "\tn = len(x)\n",
        "\tm = len(y)\n",
        "\td = np.zeros((n + 1) * (m + 1), dtype = np.uint8).reshape(n + 1, m + 1)\n",
        "\n",
        "\tfor i in range(n + 1):\n",
        "\t\tfor j in range(m + 1):\n",
        "\t\t\tif i == 0:\n",
        "\t\t\t\td[0][j] = j\n",
        "\t\t\telif j == 0:\n",
        "\t\t\t\td[i][0] = i\n",
        "\n",
        "\tfor i in range(1, n + 1):\n",
        "\t\tfor j in range(1, m + 1):\n",
        "\t\t\tif (x[i - 1] == y[j - 1]):\n",
        "\t\t\t\td[i][j] = d[i - 1][j - 1]\n",
        "\t\t\telse:\n",
        "\t\t\t\tS = d[i - 1][j - 1] + 1\n",
        "\t\t\t\tI = d[i][j - 1] + 1\n",
        "\t\t\t\tD = d[i - 1][j] + 1\n",
        "\t\t\t\td[i][j] = min(S, I, D)\n",
        "\t\n",
        "\treturn d[n][m] * 1.0 / n"
      ],
      "metadata": {
        "id": "XMR7jq3Hdpqu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}